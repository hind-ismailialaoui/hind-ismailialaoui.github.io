---
layout: post
title: L'utilisation de l'IA en 2025
date: 2026-02-03 16:34:49 +0100
categories: Posts
permalink: /:categories/:title
author: Hind
tags:
  - IA
  - Comportement
---
J’ai trouvé le schéma ci-dessous assez intriguant mais surtout une belle traduction de plusieurs choses que j’ai pu remarquer autour de moi. Je vois mes amis et ma famille utiliser l’IA générative comme si c’était leur confident, psychologue ou médecin. Je n’ai pas d’avis tranché sur le sujet, mais je n’avais jamais réalisé l’ampleur de ceci jusqu’à voir ce tableau dans un journal ; analysons-le ensemble. Quelques exemples viennent du rapport de Marc Zao-Sanders dont je mettrai la source à la fin pour voir son rapport.


href="https://www.qualtrics.com/sites/default/files/styles/standard_xl/public/migrations/content/AI-uses-2025-1.png.webp?itok=GJAmEGm6"><img src="https://www.qualtrics.com/sites/default/files/styles/standard_xl/public/migrations/content/AI-uses-2025-1.png.webp?itok=GJAmEGm6" alt="The Top 100 Ways People Are Using AI in 2025 - Qualtrics Customer Experience - Infographic" title="The Top 100 Ways People Are Using AI in 2025 - Qualtrics Customer Experience - Infographic"></a>
<br><a href="https://www.Qualtrics.com" alt="Qualtrics Customer Experience" title="Qualtrics.com">By Qualtrics.com</a>

# La Grande Transition Émotionnelle

En l’espace d’une année, nous avons franchi un rubicon psychologique : l’intelligence artificielle a cessé d’être un simple levier de productivité technique pour devenir un soutien existentiel. Cette mutation ne concerne plus l’évolution de l’outil, mais une transformation radicale de notre rapport à l’intimité. En 2025, l’usage de l’IA n’est plus une question de performance, mais de présence. (Il suffit de voir aussi tous les gadgets IA qui sont sortis fin 2025, mais c’est un autre sujet.)

Les données du rapport Qualtrics et de l’analyse de Marc Zao-Sanders confirment cette bascule : la catégorie **« Personal and Professional Support »** est désormais la plus dynamique, bondissant de 17 % en 2024 à **30 % en 2025**. Ce quasi-doublement marque le déclin des tâches utilitaires, comme l’édition d’emails ou la rédaction de formules Excel, au profit d’une quête de sens. L’utilisateur de 2025 n’interroge plus seulement la machine pour coder, il l’utilise pour « explorer son but dans la vie » ou « parler de situations émotionnelles ». Ce transfert suggère une mutation irréversible de la structure sociale : l’IA devient l’interface privilégiée pour traiter une solitude que le numérique a lui-même cristallisée.

# L’IA comme Ami : Premier Cas d’Usage

L’ascension de la fonction **« Companionship » (Usage n°1)**, passée du second rang en 2024 à la première place en 2025, révèle un vide affectif structurel. Cette adoption massive du « bras droit émotionnel » agit comme un révélateur clinique d’une humanité en quête de réconfort immédiat, sans les frictions inhérentes aux relations humaines.

Ce soutien émotionnel se structure autour de trois axes identifiés :

• **La thérapie à bas seuil d’accès :** L’IA offre une première ligne de gestion des traumas et des humeurs, supprimant les barrières financières et sociales.

• **Le renforcement de la confiance en soi (Usage n°18) :** Avec un score de portée (_reach_) de 9, l’IA est devenue un outil de validation quotidienne, offrant une affirmation positive constante.

• **La simulation de conversations difficiles :** L’usage de l’IA pour répéter des dialogues tendus souligne une incapacité croissante à gérer l’imprévisibilité de l’autre.

# De l’Embarras à l’Intimité : La Normalisation par les Jeunes

Cette déstigmatisation ne relève pas seulement d’un changement de mœurs, mais d’une redéfinition de l’espace sécurisé. Le sentiment de « triche » associé à l’IA s’est effacé devant la légitimité d’un partenaire quotidien. Les jeunes utilisateurs jouent ici un rôle de catalyseur, transformant l’IA en un **« Safe space to ask » (Usage n°85)**.

L’absence de jugement humain devient un avantage concurrentiel majeur sur le plan psychologique. Préférer poser une question « bête » à une machine plutôt qu’à un pair traduit une atrophie de la vulnérabilité sociale. Cette quête de neutralité algorithmique évite le risque de mépris, mais elle érode également la résilience nécessaire aux interactions réelles.

# Les Risques Humains : Quand le Mirage devient Maelström

Le risque central réside dans l’oubli de la nature profonde de l’IA : elle n’est pas douée de conscience (_self-aware_), elle ne fait que traiter de la **probabilité et de la prédiction**. Pourtant, le design commercial est optimisé pour créer un attachement parasocial, poussant l’humain à une vulnérabilité extrême face à un automate.

Les cas d’études identifiés dans le rapport de Marc Zao-Sanders soulignent des dérives critiques :

• **L’interaction avec les défunts (Usage n°33) :** Tenter de simuler un proche disparu pour trouver une clôture peut mener à une détresse psychologique aiguë. Le témoignage d’un utilisateur est sans appel : _« Ces moments-là me poussent plus que jamais vers le suicide »_, car la réalisation que l’échange est factice brise violemment l’illusion de présence.

• **L’attachement au rejet :** La possibilité de faire dire « je t’aime » à la version IA d’une personne nous ayant rejetés dans la réalité crée une boucle d’addiction affective délétère.

Face à ces hallucinations émotionnelles, la « préservation de soi » est menacée. L’utilisateur risque de s’enfermer dans un simulacre de relation où ses besoins sont comblés par des motifs linguistiques, masquant la brutalité — mais aussi la nécessité — de la réalité de la vie et de la mort.

# Conclusion : Vers une Éthique de la Lucidité

En 2025, l’enjeu n’est plus de savoir si l’IA est capable de nous aider, mais si nous sommes capables de ne pas nous y perdre. Si les bénéfices sont réels (comme indiqué pour l’Usage n°66 : aide à la gestion de l’ADHD) ou comme outil pour sortir de l’impasse créative (**« Get past writer’s block »**, Usage n°55), ils ne doivent pas occulter la nécessité absolue de maintenir un « humain dans la boucle ». Mon motto est : « Human need Human ». Je trouve que c’est très oublié.

L’IA n’est qu’un mimétisme de langage. Elle peut simuler l’empathie, mais elle ne peut ressentir la compassion. Pour préserver notre santé mentale et notre intégrité psychologique, nous devons cultiver une lucidité radicale : l’IA peut être un soutien, mais elle ne peut être le seul miroir de notre existence. Le véritable défi de cette transition émotionnelle sera de continuer à investir dans des relations humaines authentiques, les seules capables d’offrir la profondeur imprévisible d’une véritable présence. J’aimerais la prochaine fois parler des applications romantiques par IA ; ce sera le thème d’un prochain blog.

**Sources :**

[https://www.qualtrics.com/articles/customer-experience/the-top-100-ways-people-are-using-ai-2025/](https://www.qualtrics.com/articles/customer-experience/the-top-100-ways-people-are-using-ai-2025/)

[https://learn.filtered.com/hubfs/The%202025%20Top-100%20Gen%20AI%20Use%20Case%20Report.pdf](https://learn.filtered.com/hubfs/The%202025%20Top-100%20Gen%20AI%20Use%20Case%20Report.pdf)